{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2：基线回测 — SMA 交叉（backtesting.py）\n",
    "\n",
    "目标：\n",
    "- 使用 backtesting.py 在 Day1 下载的数据上实现 SMA(50,200) 交叉策略；\n",
    "- 在回测中模拟手续费、滑点、最大仓位等执行约束；\n",
    "- 导出回测统计与交易明细（CSV），并绘制回测结果图；\n",
    "- 为 Day3 的 ML 信号留出接口（保存信号列）。\n",
    "\n",
    "说明：建议在 WSL2 的虚拟环境中运行（与 Day1 相同 venv/conda）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚拟环境与依赖（在激活 venv 后运行）\n",
    "在 WSL2 终端中，如尚未安装 backtesting.py，可运行：\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install backtesting pandas pyarrow matplotlib joblib\n",
    "# 可选：若想用 backtrader 或其他框架：pip install backtrader\n",
    "```\n",
    "在 notebook 单元中可使用 `!pip install ...` 临时安装，但长期建议在外部激活 venv 并安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "platform Windows-11-10.0.26100-SP0\n",
      "pandas 2.3.3\n",
      "numpy 2.3.4\n"
     ]
    }
   ],
   "source": [
    "# 环境与库检查（在激活 venv 后运行）\n",
    "import sys\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('python', sys.version)\n",
    "print('platform', platform.platform())\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取 Day1 的数据（parquet/csv）\n",
    "本单元会尝试从 `data/` 读取 parquest 文件。你可以修改 `symbol` 变量以读取别的文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found parquet files: ['../data\\\\sh601988.parquet']\n",
      "found csv files: ['../data\\\\sh601988.csv']\n",
      "Loading file: ../data\\sh601988.parquet\n",
      "            Open  High   Low  Close        Volume        amount  \\\n",
      "Date                                                              \n",
      "2006-07-05  3.99  4.05  3.76   3.79  1.763902e+09  6.846112e+09   \n",
      "2006-07-06  3.75  3.76  3.69   3.72  3.725565e+08  1.386101e+09   \n",
      "2006-07-07  3.72  3.73  3.66   3.68  2.097986e+08  7.736735e+08   \n",
      "2006-07-10  3.68  3.72  3.66   3.70  1.127236e+08  4.161987e+08   \n",
      "2006-07-11  3.71  3.78  3.67   3.75  1.356450e+08  5.027508e+08   \n",
      "\n",
      "            outstanding_share  turnover  \n",
      "Date                                     \n",
      "2006-07-05       3.454547e+09  0.510603  \n",
      "2006-07-06       3.454547e+09  0.107845  \n",
      "2006-07-07       3.454547e+09  0.060731  \n",
      "2006-07-10       3.454547e+09  0.032631  \n",
      "2006-07-11       3.454547e+09  0.039266  \n",
      "length: 4688\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 自动寻找 data 目录下的 parquet 文件\n",
    "data_dir = '../data'\n",
    "parquets = glob(os.path.join(data_dir, '*.parquet'))\n",
    "csvs = glob(os.path.join(data_dir, '*.csv'))\n",
    "print('found parquet files:', parquets)\n",
    "print('found csv files:', csvs)\n",
    "\n",
    "# 指定 symbol（若未指定，默认使用第一个 parquet）\n",
    "symbol = None\n",
    "if parquets:\n",
    "    path = parquets[0] if symbol is None else os.path.join(data_dir, f\"{symbol}.parquet\")\n",
    "elif csvs:\n",
    "    path = csvs[0] if symbol is None else os.path.join(data_dir, f\"{symbol}.csv\")\n",
    "else:\n",
    "    raise FileNotFoundError('No parquet or csv files found in data/. Run Day1 notebook first.')\n",
    "\n",
    "print('Loading file:', path)\n",
    "if path.endswith('.parquet'):\n",
    "    df = pd.read_parquet(path)\n",
    "else:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "# 规范列名到 backtesting.py 期望的格式： 'Open','High','Low','Close','Volume'\n",
    "df = df.rename(columns={\n",
    "    'open':'Open', 'high':'High', 'low':'Low', 'close':'Close', 'volume':'Volume', 'date':'Date'\n",
    "})\n",
    "\n",
    "# 如果有小写列名不同，尝试更多映射\n",
    "lower_cols = {c.lower(): c for c in df.columns}\n",
    "if 'date' in lower_cols:\n",
    "    df = df.rename(columns={lower_cols['date']:'Date'})\n",
    "\n",
    "if 'Date' in df.columns:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # backtesting.py 要求索引为 DatetimeIndex\n",
    "    df = df.set_index('Date')\n",
    "\n",
    "df = df.sort_index()\n",
    "print(df.head())\n",
    "print('length:', len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义 SMA Cross 策略（backtesting.py）\n",
    "我们将使用 backtesting.py 的 Strategy 类实现，包含参数化的短期/长期均线、最大持仓比例与手续费/滑点设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23afd4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预处理完成，开始回测...\n",
      "数据长度: 4489\n",
      "数据时间范围: 2007-04-27 00:00:00 到 2025-11-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理 - 计算移动平均线\n",
    "df['SMA50'] = df['Close'].rolling(window=50).mean()\n",
    "df['SMA200'] = df['Close'].rolling(window=200).mean()\n",
    "\n",
    "# 删除包含NaN的行（因为移动平均在开头会产生NaN）\n",
    "df_clean = df.dropna().copy()\n",
    "\n",
    "print('数据预处理完成，开始回测...')\n",
    "print(f'数据长度: {len(df_clean)}')\n",
    "print(f'数据时间范围: {df_clean.index[0]} 到 {df_clean.index[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\backtesting\\_plotting.py:55: UserWarning: Jupyter Notebook detected. Setting Bokeh output to notebook. This may not work in Jupyter clients without JavaScript support, such as old IDEs. Reset with `backtesting.set_bokeh_output(notebook=False)`.\n",
      "  warnings.warn('Jupyter Notebook detected. '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f66adfbc-98fa-41ba-adaa-0ebd892db7fe\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f66adfbc-98fa-41ba-adaa-0ebd892db7fe\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.8.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f66adfbc-98fa-41ba-adaa-0ebd892db7fe\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from backtesting import Backtest, Strategy\n",
    "from backtesting.lib import crossover\n",
    "import pandas as pd\n",
    "\n",
    "# class SmaCrossStrategy(Strategy):\n",
    "#     # 可调参数\n",
    "#     n1 = 50  # 短期均线\n",
    "#     n2 = 200 # 长期均线\n",
    "#     max_pct = 0.2  # 最大仓位占比（例如 0.2 = 20%）\n",
    "\n",
    "#     def init(self):\n",
    "#         # 使用 Strategy.I 计算指标\n",
    "#         self.sma1 = self.I(pd.Series.rolling, self.data.Close, window=self.n1).mean()\n",
    "#         self.sma2 = self.I(pd.Series.rolling, self.data.Close, window=self.n2).mean()\n",
    "\n",
    "#     def next(self):\n",
    "#         # 如果短期上穿长期，且未持仓或持仓为0，则买入到最大仓位\n",
    "#         if crossover(self.sma1, self.sma2):\n",
    "#             cash = self.equity - self.position.pl\n",
    "#             size = int((self.max_pct * self.equity) / self.data.Close[-1])\n",
    "#             if size > 0:\n",
    "#                 # 市价买入\n",
    "#                 self.buy(size=size)\n",
    "#         elif crossover(self.sma2, self.sma1):\n",
    "#             # 平仓\n",
    "#             if self.position.size > 0:\n",
    "#                 self.position.close()\n",
    "\n",
    "#     # 可在需要时添加 on_order/on_execution 回调以记录更多执行细节\n",
    "    \n",
    "# print('Strategy defined')\n",
    "\n",
    "class SmaCrossStrategy(Strategy):\n",
    "    n1 = 50\n",
    "    n2 = 200\n",
    "    max_pct = 0.2\n",
    "\n",
    "    def init(self):\n",
    "        # 预计算的指标\n",
    "        self.sma1 = self.data.SMA50\n",
    "        self.sma2 = self.data.SMA200\n",
    "        \n",
    "        # 记录信号（可选，用于分析）\n",
    "        self.signal = None\n",
    "\n",
    "    def next(self):\n",
    "        # 计算信号\n",
    "        prev_sma1 = self.sma1[-2] if len(self.sma1) > 1 else self.sma1[-1]\n",
    "        prev_sma2 = self.sma2[-2] if len(self.sma2) > 1 else self.sma2[-1]\n",
    "        \n",
    "        current_sma1 = self.sma1[-1]\n",
    "        current_sma2 = self.sma2[-1]\n",
    "        \n",
    "        # 判断金叉死叉\n",
    "        golden_cross = (prev_sma1 <= prev_sma2) and (current_sma1 > current_sma2)\n",
    "        death_cross = (prev_sma1 >= prev_sma2) and (current_sma1 < current_sma2)\n",
    "        \n",
    "        if golden_cross and not self.position:\n",
    "            # 金叉买入信号\n",
    "            available_cash = self.equity - self.position.pl\n",
    "            price = self.data.Close[-1]\n",
    "            size = int((self.max_pct * self.equity) / price)\n",
    "            \n",
    "            if size > 0 and available_cash >= size * price:\n",
    "                self.buy(size=size)\n",
    "                self.signal = 1  # 买入信号\n",
    "                \n",
    "        elif death_cross and self.position and self.position.size > 0:\n",
    "            # 死叉卖出信号\n",
    "            self.position.close()\n",
    "            self.signal = -1  # 卖出信号\n",
    "        else:\n",
    "            self.signal = 0  # 无信号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行回测并导出结果\n",
    "我们会配置初始资金、手续费（按比例）、滑点（绝对值或点数）等。\n",
    "回测完成后将保存统计到 `reports/`，并把交易明细导出为 CSV。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start                     2007-04-27 00:00:00\n",
      "End                       2025-11-10 00:00:00\n",
      "Duration                   6772 days 00:00:00\n",
      "Exposure Time [%]                         0.0\n",
      "Equity Final [$]                     100000.0\n",
      "Equity Peak [$]                      100000.0\n",
      "Return [%]                                0.0\n",
      "Buy & Hold Return [%]                 0.71174\n",
      "Return (Ann.) [%]                         0.0\n",
      "Volatility (Ann.) [%]                     0.0\n",
      "CAGR [%]                                  0.0\n",
      "Sharpe Ratio                              NaN\n",
      "Sortino Ratio                             NaN\n",
      "Calmar Ratio                              NaN\n",
      "Alpha [%]                                 0.0\n",
      "Beta                                      0.0\n",
      "Max. Drawdown [%]                        -0.0\n",
      "Avg. Drawdown [%]                         NaN\n",
      "Max. Drawdown Duration                    NaN\n",
      "Avg. Drawdown Duration                    NaN\n",
      "# Trades                                    0\n",
      "Win Rate [%]                              NaN\n",
      "Best Trade [%]                            NaN\n",
      "Worst Trade [%]                           NaN\n",
      "Avg. Trade [%]                            NaN\n",
      "Max. Trade Duration                       NaN\n",
      "Avg. Trade Duration                       NaN\n",
      "Profit Factor                             NaN\n",
      "Expectancy [%]                            NaN\n",
      "SQN                                       NaN\n",
      "Kelly Criterion                           NaN\n",
      "_strategy                    SmaCrossStrategy\n",
      "_equity_curve                           Eq...\n",
      "_trades                   Empty DataFrame\n",
      "...\n",
      "dtype: object\n",
      "Saved stats to ../reports\\sma_backtest_stats.csv\n",
      "Error extracting trades: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Plotted backtest (interactive HTML saved in reports)\n",
      "\n",
      "=== 回测结果摘要 ===\n",
      "最终净值: 100000.00\n",
      "总回报率: 0.00%\n",
      "年化回报率: 0.00%\n",
      "最大回撤: -0.00%\n",
      "总交易次数: 0\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.makedirs('../reports', exist_ok=True)\n",
    "\n",
    "# from backtesting import Backtest\n",
    "\n",
    "# # 配置参数\n",
    "# cash = 100000  # 初始资金\n",
    "# commission = 0.0003  # 手续费比例（示例）\n",
    "# slippage = 0.01  # 滑点（每股价格偏差，示例）\n",
    "\n",
    "# # backtesting.py 的 slippage 参数可以通过 'slippage' 或自定义委托模型实现。\n",
    "# bt = Backtest(\n",
    "#     df,\n",
    "#     SmaCrossStrategy,\n",
    "#     cash=cash,\n",
    "#     commission=commission,\n",
    "#     exclusive_orders=True,\n",
    "#     trade_on_close=False,\n",
    "#     hedging=False,\n",
    "# )\n",
    "\n",
    "# stats = bt.run()\n",
    "# print(stats)\n",
    "\n",
    "# # 保存统计到 CSV/JSON\n",
    "# stats_df = pd.DataFrame(stats)\n",
    "# stats_path = os.path.join('reports', 'sma_backtest_stats.csv')\n",
    "# try:\n",
    "#     # backtesting.run() 返回的是字典/Series-like，有时直接转换会有问题；这里把关键字段提取为 DataFrame\n",
    "#     pd.Series(stats).to_frame('value').to_csv(stats_path)\n",
    "#     print('Saved stats to', stats_path)\n",
    "# except Exception as e:\n",
    "#     print('Failed to save stats:', e)\n",
    "\n",
    "# # 导出交易明细\n",
    "# trades = bt.get_trades()\n",
    "# trades_df = trades.to_df()\n",
    "# trades_path = os.path.join('reports', 'sma_backtest_trades.csv')\n",
    "# trades_df.to_csv(trades_path, index=False)\n",
    "# print('Saved trades to', trades_path)\n",
    "\n",
    "# # 画图并保存\n",
    "# fig = bt.plot(filename=os.path.join('reports', 'sma_backtest.html'))\n",
    "# print('Plotted backtest (interactive HTML saved in reports)')\n",
    "import os\n",
    "os.makedirs('../reports', exist_ok=True)\n",
    "\n",
    "from backtesting import Backtest\n",
    "\n",
    "# 配置参数\n",
    "cash = 100000  # 初始资金\n",
    "commission = 0.0003  # 手续费比例（示例）\n",
    "slippage = 0.01  # 滑点（每股价格偏差，示例）\n",
    "\n",
    "# 使用已经预处理好的数据（包含SMA指标）\n",
    "bt = Backtest(\n",
    "    df_clean,  # 使用预处理后的数据，不是原始数据\n",
    "    SmaCrossStrategy,\n",
    "    cash=cash,\n",
    "    commission=commission,\n",
    "    exclusive_orders=True,\n",
    "    trade_on_close=False,\n",
    "    hedging=False,\n",
    ")\n",
    "\n",
    "stats = bt.run()\n",
    "print(stats)\n",
    "\n",
    "# 保存统计到 CSV/JSON\n",
    "stats_path = os.path.join('../reports', 'sma_backtest_stats.csv')\n",
    "try:\n",
    "    # backtesting.run() 返回的是字典/Series-like\n",
    "    pd.Series(stats).to_frame('value').to_csv(stats_path)\n",
    "    print('Saved stats to', stats_path)\n",
    "except Exception as e:\n",
    "    print('Failed to save stats:', e)\n",
    "\n",
    "# 导出交易明细 - 正确的方法\n",
    "try:\n",
    "    # 方法1: 从stats中获取\n",
    "    if hasattr(stats, '_trades') and stats._trades:\n",
    "        trades_df = pd.DataFrame([{\n",
    "            'EntryBar': trade.entry_bar,\n",
    "            'ExitBar': trade.exit_bar,\n",
    "            'EntryPrice': trade.entry_price,\n",
    "            'ExitPrice': trade.exit_price,\n",
    "            'PnL': trade.pl,\n",
    "            'ReturnPct': trade.pl_pct,\n",
    "            'Size': trade.size,\n",
    "            'EntryTime': trade.entry_time,\n",
    "            'ExitTime': trade.exit_time\n",
    "        } for trade in stats._trades])\n",
    "    else:\n",
    "        # 方法2: 尝试其他属性名\n",
    "        trades_df = pd.DataFrame()\n",
    "        \n",
    "    if not trades_df.empty:\n",
    "        trades_path = os.path.join('../reports', 'sma_backtest_trades.csv')\n",
    "        trades_df.to_csv(trades_path, index=False)\n",
    "        print('Saved trades to', trades_path)\n",
    "        print(f'交易数量: {len(trades_df)}')\n",
    "    else:\n",
    "        print('No trades found in the backtest results')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f'Error extracting trades: {e}')\n",
    "\n",
    "# 画图并保存\n",
    "try:\n",
    "    fig = bt.plot(filename=os.path.join('../reports', 'sma_backtest.html'))\n",
    "    print('Plotted backtest (interactive HTML saved in reports)')\n",
    "except Exception as e:\n",
    "    print(f'Error plotting: {e}')\n",
    "\n",
    "# 简单诊断与性能摘要\n",
    "print(\"\\n=== 回测结果摘要 ===\")\n",
    "print(f\"最终净值: {stats['Equity Final [$]']:.2f}\")\n",
    "print(f\"总回报率: {stats['Return [%]']:.2f}%\")\n",
    "print(f\"年化回报率: {stats['Return (Ann.) [%]']:.2f}%\")\n",
    "if 'Sharpe Ratio' in stats and not np.isnan(stats['Sharpe Ratio']):\n",
    "    print(f\"夏普比率: {stats['Sharpe Ratio']:.2f}\")\n",
    "print(f\"最大回撤: {stats['Max. Drawdown [%]']:.2f}%\")\n",
    "print(f\"总交易次数: {stats['# Trades']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单诊断与性能摘要\n",
    "计算并显示交易次数、胜率、平均盈亏、最大回撤、年化收益等简单指标（部分指标已在 stats 中，但我们也直接计算一些常见值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trades_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# trades_df 来自上面导出的交易明细（若为空，请确认策略有交易）\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrades_df\u001b[49m.empty:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNo trades generated by the strategy. Consider adjusting parameters or checking data length.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'trades_df' is not defined"
     ]
    }
   ],
   "source": [
    "# trades_df 来自上面导出的交易明细（若为空，请确认策略有交易）\n",
    "if trades_df.empty:\n",
    "    print('No trades generated by the strategy. Consider adjusting parameters or checking data length.')\n",
    "else:\n",
    "    trades_df['PnL'] = trades_df['PnL']\n",
    "    total_trades = len(trades_df)\n",
    "    wins = (trades_df['PnL'] > 0).sum()\n",
    "    win_rate = wins / total_trades if total_trades>0 else float('nan')\n",
    "    avg_pnl = trades_df['PnL'].mean()\n",
    "    print(f'total_trades={total_trades}, wins={wins}, win_rate={win_rate:.2%}, avg_pnl={avg_pnl:.4f}')\n",
    "    print('Top 5 trades by PnL:')\n",
    "    display(trades_df.sort_values('PnL', ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可选：把策略信号保存为列以便 Day3 使用（例如 ML 层复查）\n",
    "我们把均线信号添加到原始价格数据并保存为 parquet，Day3 可以直接读取并做特征叠加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m df_signals[\u001b[33m'\u001b[39m\u001b[33msma_cross_signal\u001b[39m\u001b[33m'\u001b[39m] = (df_signals[\u001b[33m'\u001b[39m\u001b[33msma_short\u001b[39m\u001b[33m'\u001b[39m] > df_signals[\u001b[33m'\u001b[39m\u001b[33msma_long\u001b[39m\u001b[33m'\u001b[39m]).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      6\u001b[39m signals_path = os.path.join(\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msignals_sma_50_200.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdf_signals\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSaved signals to\u001b[39m\u001b[33m'\u001b[39m, signals_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3124\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3044\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3045\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3120\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3132\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:482\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m impl = get_engine(engine)\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io.BytesIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:199\u001b[39m, in \u001b[36mPyArrowImpl.write\u001b[39m\u001b[34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m     merged_metadata = {**existing_metadata, **df_metadata}\n\u001b[32m    197\u001b[39m     table = table.replace_schema_metadata(merged_metadata)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    207\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(path_or_handle, io.BufferedWriter)\n\u001b[32m    208\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path_or_handle, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    209\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle.name, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[32m    210\u001b[39m ):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle.name, \u001b[38;5;28mbytes\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\资料库文档\\量化\\quant_project\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "# 计算信号列并保存\n",
    "df_signals = df.copy()\n",
    "df_signals['sma_short'] = df_signals['Close'].rolling(50).mean()\n",
    "df_signals['sma_long'] = df_signals['Close'].rolling(200).mean()\n",
    "df_signals['sma_cross_signal'] = (df_signals['sma_short'] > df_signals['sma_long']).astype(int)\n",
    "signals_path = os.path.join('data', 'signals_sma_50_200.parquet')\n",
    "df_signals.reset_index().to_parquet(signals_path, index=False)\n",
    "print('Saved signals to', signals_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步建议\n",
    "- 若回测生成过多交易或表现不稳定：尝试调整 `n1/n2`、`max_pct`，或增加最小持仓时间等规则（避免频繁交易）。\n",
    "- 若希望更接近实盘：在 Day4 模拟 T+1、涨跌停与最小下单单位（手数）等规则；若使用券商 API，也需实现订单执行层并考虑滑点/拒单情况。\n",
    "- Day3 将引入特征工程与 ML 信号：你可以直接在 Day3 使用本单元保存的 signals parquet 文件作为基线特征。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": null,
  "kernelspec": {
   "display_name": "Python量化 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
